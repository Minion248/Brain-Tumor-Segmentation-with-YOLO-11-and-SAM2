{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVX3djYQPrwa"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q opencv-python matplotlib torch torchvision\n",
        "!pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install -q git+https://github.com/ultralytics/ultralytics.git\n",
        "\n",
        "# Clone Segment Anything repo\n",
        "!git clone https://github.com/facebookresearch/segment-anything.git\n",
        "%cd segment-anything\n",
        "\n",
        "# Download SAM2 checkpoint\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "from ultralytics import YOLO\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SAM model\n",
        "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
        "model_type = \"vit_b\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "# Load YOLO model\n",
        "yolo = YOLO(\"yolov8n.pt\")  # Replace with YOLOv11 model if you have custom weights\n"
      ],
      "metadata": {
        "id": "ySZe_aKvPzfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload ZIP file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get filename\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Extract contents to \"dataset\" folder\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")\n",
        "\n",
        "# Recursively find all image files\n",
        "image_files = []\n",
        "for root, dirs, files_in_dir in os.walk(\"dataset\"):\n",
        "    for file in files_in_dir:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_files.append(os.path.join(root, file))\n",
        "\n",
        "# Check if images were found\n",
        "if len(image_files) == 0:\n",
        "    print(\"‚ùå No image files found in the ZIP.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found {len(image_files)} image(s). Showing the first one:\")\n",
        "\n",
        "    # Show the first image\n",
        "    import cv2\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    image = cv2.imread(image_files[0])\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"First Image from ZIP\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "fTeFhKy6P2qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure YOLO and SAM are already loaded as `yolo` and `predictor` from earlier cells\n",
        "\n",
        "for idx, image_path in enumerate(image_files):\n",
        "    print(f\"üîç Processing image {idx+1}/{len(image_files)}: {image_path}\")\n",
        "\n",
        "    # Read and convert image\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run YOLOv8/YOLOv11\n",
        "    results = yolo(image_rgb)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
        "\n",
        "    # Set image for SAM\n",
        "    predictor.set_image(image_rgb)\n",
        "\n",
        "    # Process each bounding box\n",
        "    for box_idx, box in enumerate(boxes):\n",
        "        x0, y0, x1, y1 = box\n",
        "        input_box = np.array([x0, y0, x1, y1])\n",
        "        masks, scores, logits = predictor.predict(box=input_box, multimask_output=True)\n",
        "\n",
        "        # Show each mask\n",
        "        for i, mask in enumerate(masks):\n",
        "            plt.figure(figsize=(5, 5))\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.imshow(mask, alpha=0.6)\n",
        "            plt.title(f\"Image {idx+1}, Box {box_idx+1}, Mask {i+1}, Score: {scores[i]:.2f}\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "-3CoxcjvP5hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# Create directory for saving masks\n",
        "os.makedirs(\"segmentation_results\", exist_ok=True)\n",
        "\n",
        "# Collect info for all masks\n",
        "results_data = []\n",
        "\n",
        "for idx, image_path in enumerate(image_files):\n",
        "    print(f\"üíæ Saving masks for image {idx+1}/{len(image_files)}: {image_path}\")\n",
        "\n",
        "    # Read and convert\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # Run YOLO\n",
        "    results = yolo(image_rgb)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
        "\n",
        "    # Set image for SAM\n",
        "    predictor.set_image(image_rgb)\n",
        "\n",
        "    for box_idx, box in enumerate(boxes):\n",
        "        x0, y0, x1, y1 = box\n",
        "        input_box = np.array([x0, y0, x1, y1])\n",
        "        masks, scores, _ = predictor.predict(box=input_box, multimask_output=True)\n",
        "\n",
        "        for i, mask in enumerate(masks):\n",
        "            # Generate mask filename\n",
        "            mask_filename = f\"{filename}_box{box_idx+1}_mask{i+1}.png\"\n",
        "            mask_path = os.path.join(\"segmentation_results\", mask_filename)\n",
        "\n",
        "            # Convert and save mask\n",
        "            mask_image = (mask * 255).astype(np.uint8)\n",
        "            cv2.imwrite(mask_path, mask_image)\n",
        "\n",
        "            # Save info\n",
        "            results_data.append({\n",
        "                \"image\": filename,\n",
        "                \"box_index\": box_idx + 1,\n",
        "                \"mask_index\": i + 1,\n",
        "                \"score\": round(float(scores[i]), 4),\n",
        "                \"mask_file\": mask_filename,\n",
        "                \"box\": f\"{x0},{y0},{x1},{y1}\"\n",
        "            })\n",
        "\n",
        "# Save all results as CSV\n",
        "df = pd.DataFrame(results_data)\n",
        "df.to_csv(\"segmentation_results/mask_metadata.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ All masks and their metadata saved to `segmentation_results/` folder.\")\n"
      ],
      "metadata": {
        "id": "J4bo1Dz5QAKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}